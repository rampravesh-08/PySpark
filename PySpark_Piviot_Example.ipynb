{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivot and Unpivot a Spark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('C:\\\\spark\\\\spark-3.0.0-hadoop2.7')\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Basic').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ESS17001DXB0559:4044\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.0-preview2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Basic</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x25bf3ee5608>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = spark.createDataFrame([\n",
    "    (\"Banana\",1000,\"USA\"), (\"Carrots\",1500,\"USA\"), (\"Beans\",1600,\"USA\"),\n",
    "      (\"Orange\",2000,\"USA\"),(\"Orange\",2000,\"USA\"),(\"Banana\",400,\"China\"),\n",
    "      (\"Carrots\",1200,\"China\"),(\"Beans\",1500,\"China\"),(\"Orange\",4000,\"China\"),\n",
    "      (\"Banana\",2000,\"Canada\"),(\"Carrots\",2000,\"Canada\"),(\"Beans\",2000,\"Mexico\")\n",
    "], [\"Product\",\"Amount\",\"Country\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-------+\n",
      "|Product|Amount|Country|\n",
      "+-------+------+-------+\n",
      "| Banana|  1000|    USA|\n",
      "|Carrots|  1500|    USA|\n",
      "|  Beans|  1600|    USA|\n",
      "| Orange|  2000|    USA|\n",
      "| Orange|  2000|    USA|\n",
      "| Banana|   400|  China|\n",
      "|Carrots|  1200|  China|\n",
      "|  Beans|  1500|  China|\n",
      "| Orange|  4000|  China|\n",
      "| Banana|  2000| Canada|\n",
      "|Carrots|  2000| Canada|\n",
      "|  Beans|  2000| Mexico|\n",
      "+-------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-----+------+----+\n",
      "|Product|Canada|China|Mexico| USA|\n",
      "+-------+------+-----+------+----+\n",
      "| Orange|  null| 4000|  null|4000|\n",
      "|  Beans|  null| 1500|  2000|1600|\n",
      "| Banana|  2000|  400|  null|1000|\n",
      "|Carrots|  2000| 1200|  null|1500|\n",
      "+-------+------+-----+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_df.groupBy('Product').pivot('Country').sum('Amount').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-----+-------+------+\n",
      "|Country|Banana|Beans|Carrots|Orange|\n",
      "+-------+------+-----+-------+------+\n",
      "|  China|   400| 1500|   1200|  4000|\n",
      "|    USA|  1000| 1600|   1500|  4000|\n",
      "| Mexico|  null| 2000|   null|  null|\n",
      "| Canada|  2000| null|   2000|  null|\n",
      "+-------+------+-----+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_df.groupBy('Country').pivot('Product').sum('Amount').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+------+------+\n",
      "|Product| USA|China|Canada|Mexico|\n",
      "+-------+----+-----+------+------+\n",
      "| Orange|4000| 4000|  null|  null|\n",
      "|  Beans|1600| 1500|  null|  2000|\n",
      "| Banana|1000|  400|  2000|  null|\n",
      "|Carrots|1500| 1200|  2000|  null|\n",
      "+-------+----+-----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Following both approach will produce same output with better performance\n",
    "\n",
    "# Spark 2.0 on-wards performance has been improved on Pivot, however, if you are using lower version; note that pivot is a very expensive operation hence, it is recommended to provide column data (if known) as an argument to function as shown below.\n",
    "data_df.groupBy('Product').pivot('Country',[\"USA\",\"China\",\"Canada\",\"Mexico\"]).sum('Amount').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-----+------+----+\n",
      "|Product|Canada|China|Mexico| USA|\n",
      "+-------+------+-----+------+----+\n",
      "| Orange|  null| 4000|  null|4000|\n",
      "|  Beans|  null| 1500|  2000|1600|\n",
      "| Banana|  2000|  400|  null|1000|\n",
      "|Carrots|  2000| 1200|  null|1500|\n",
      "+-------+------+-----+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_df.groupBy('Product','Country').sum('Amount').groupBy('Product').pivot('Country').sum('sum(Amount)').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|Product|       avg(Amount)|\n",
      "+-------+------------------+\n",
      "| Orange|2666.6666666666665|\n",
      "|  Beans|            1700.0|\n",
      "| Banana|1133.3333333333333|\n",
      "|Carrots|1566.6666666666667|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_df.groupBy('Product').agg({'Amount': 'mean'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<b'Product[0][0]'>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
